I"
<h1 id="sampling-method">Sampling Method</h1>

<blockquote>
  <p>Since there are some problems about mathjax, I also upload the pdf version <a href="https://denglinsui.github.io/pdf/Bayesian/01.pdf" target="_blank">「Bayesian」1 Sampling Method</a>.</p>

</blockquote>

<h2 id="rejection-sampling">Rejection Sampling</h2>

<h3 id="goal">Goal</h3>

<p>Sampling $X\sim p(x)$.</p>

<h3 id="algorithm">Algorithm</h3>

<ol>
  <li>Generate $X \sim q(x)$</li>
  <li>Accept $X$ with probability $\frac{p(x)}{M q(x)}$</li>
</ol>

<h3 id="disccusion">Disccusion</h3>

<ul>
  <li>We require $Mq(x)$ cover $p(x)$</li>
  <li>The acceptance rate is $1/M$.</li>
</ul>

<h2 id="matropolis-hasting-algorithm">Matropolis-Hasting Algorithm</h2>

<h3 id="goal-1">Goal</h3>

<p>The target density is $\pi(x)$, for which we know its unnormalized density
function $\pi_u(x)$.</p>

<h3 id="algorithm-1">Algorithm</h3>

<ol>
  <li>
    <p>Generate $Y_{t} \sim q\left(y \mid X^{(t)}\right)$</p>
  </li>
  <li>
    <p>Compute $\rho\left(X^{(t)}, Y_{t}\right)$ with $\rho(x, y)=\min \left(1, \frac{\pi_{u}(y) q(x \mid y)}{\pi_{u}(x) q(y \mid x)}\right)$</p>
  </li>
  <li>
    <p>Take</p>
  </li>
</ol>

\[X^{(t+1)}=\left\{\begin{array}{ll}
  Y_{t} &amp; \text { with prob } \rho\left(X^{(t)}, Y_{t}\right) \\
  X^{(t)} &amp; \text { with prob } 1-\rho\left(X^{(t)}, Y_{t}\right)
  \end{array}\right.\]

<h3 id="variants">Variants</h3>

<ul>
  <li><strong>Symmetric Metropolis Algorithm</strong>: $q(y\mid x)=q(x\mid y)$;</li>
  <li><strong>Random Walk Metropolis-Hastings</strong>: $q(y\mid x)=q(y-x)$;</li>
  <li><strong>Indepencence Sampler</strong>: $q(y\mid x)=q(y)$;</li>
  <li><strong>Langevin algrithm</strong>: $q(y\mid x)=N\left(X^t+(\delta / 2) \nabla \log \pi\left(X^{t}\right), \delta\right)$</li>
</ul>

<h3 id="discussion">Discussion</h3>

<ul>
  <li>
    <p>The transition kernel is:
\(k(x, y)=\underbrace{q(y \mid x) \rho(x, y)}_{\text {Propose y and accept }}+\underbrace{(1-r(x)) \delta_{x}(y)}_{\text {Reject, stay at } x}\)
where $r(x):=P(\text { Accept })=\int q(y \mid x) \rho(x, y) d y$, the probability that new generated $Y_{t+1}$ gets accepted.</p>
  </li>
  <li>
    <p>The MH chain satisfies the detailed balanced condition $K(y, x) \pi(y)=K(x, y) \pi(x)$.</p>
  </li>
  <li>
    <p>Independence sampler requires $\pi(y) \leq M q(y)$, the acceptance probability is at least $1/M$ when stationary and MC is uniformly ergodic
\(\left\|K^{n}(x, \cdot)-\pi\right\|_{T V} \leq 2\left(1-\frac{1}{M}\right)^{n}\)</p>
  </li>
</ul>

<h2 id="langenvin-algorithm">Langenvin Algorithm</h2>

<h3 id="goal-2">Goal</h3>

<p>Finding the maximum of a positive function, in some sense, is equivalent to finding the mode of a probability function without knowing constant. So, we can consider the question from the opposite direction, that is, finding the “distribution” of the positive function.</p>

<p>Here, consider the Langevin diffusion $L_t$ defined by the stochastic differential equation<br />
\(d L_{t}=d B_{t}+\frac{1}{2} \nabla \log \pi\left(L_{t}\right) d t\)</p>

<p>where $B_t$ is a standard Brownian motion</p>

<h3 id="algorithm-2">Algorithm</h3>

<ol>
  <li>
    <p>Generate next $Y_{t}$ by $Y_{t}=X^{(t)}+\frac{\sigma^{2}}{2} \nabla \log \pi_{u}\left(X^{(t)}\right)+\sigma \epsilon_{t}$, where $\epsilon_t$ is from standard Gaussion distribution.</p>
  </li>
  <li>
    <p>Compute $\rho\left(X^{(t)}, Y_{t}\right)$ with $\rho(x, y)=\min {1, \gamma(x, y)}$ with
\(\gamma(x, y)=\frac{\pi_{u}(y) \times \exp \left\{-\left\|x-y-\frac{\sigma^{2}}{2} \nabla \log \pi_{u}(y)\right\|^{2} /\left(2 \sigma^{2}\right)\right\}}{\pi_{u}(x) \times \exp \left\{-\left\|y-x-\frac{\sigma^{2}}{2} \nabla \log \pi_{u}(x)\right\|^{2} /\left(2 \sigma^{2}\right)\right\}}\)</p>
  </li>
  <li>
    <p>Take</p>
  </li>
</ol>

\[X^{(t+1)}=\left\{\begin{array}{ll}
  Y_{t} &amp; \text { with prob } \rho\left(X^{(t)}, Y_{t}\right) \\
  X^{(t)} &amp; \text { with prob } 1-\rho\left(X^{(t)}, Y_{t}\right)
  \end{array}\right.\]

<h3 id="disccusion-1">Disccusion</h3>

<ul>
  <li>The isotropic diffusion might be ineffcient for strongly correlated variables. The issue can be circumvented by employing a preconditioning matrix $M$ such that</li>
</ul>

\[Y_{t}=X^{(t)}+\frac{\sigma^{2}}{2} \mathrm{M} \nabla \log \pi_{u}\left(X^{(t)}\right)+\sigma \mathrm{M}^{1 / 2} \epsilon_{t}\]

<h2 id="hamiltonian-mcmc">Hamiltonian MCMC</h2>

<h3 id="goal-3">Goal</h3>

<p>Target distribution $\pi(x)\propto\exp(-U(x))$, $U(x)$ is a potential. Augment the parameter space $\mathcal{X}$ to $\mathcal{X}\times\mathcal{V}$ and the target distribution $\pi(x)$ to the <em>canonical distribution</em> $\pi(x,v)=\pi(v\mid x)\pi(x)$.</p>

<p>For simplicity $\pi(v \mid x) \propto \exp \left(-v^{T} \mathbf{M}^{-1} v\right)$. Define the Hamiltionian as $H(x, v)=-\log \pi(x, v)$.</p>

<p>To summary, we want to sample $x\sim\pi$, but we sample $(x,v)$ firstly and drop $v$. Then, the marginal is still the target distribution.</p>

<h3 id="algorithm-3">Algorithm</h3>

<ol>
  <li>Generate next $Y_t=X^{(t)}-\frac{\epsilon^{2}}{2} \frac{\partial U}{\partial x}\left(X^{(t)}\right)+\epsilon \mathbf{M}^{-1} v^{(t)}$</li>
  <li>Accept it with the probability $\min \left(1, \exp \left(-H\left(x^{\prime}, v^{\prime}\right)+H(x, v)\right)\right)$</li>
</ol>

<h2 id="stochastic-hmc">Stochastic HMC</h2>

<h3 id="goal-4">Goal</h3>

<p>The Hamiltonian MCMC has acceptance procedure. With the idea of stochastic HMC, there is no need to include the acceptance procedure.</p>

<p>Consider a generic stochastic dynamics
\(d x=\mu(x) d t+\sqrt{2} \sigma(x) d B_{t}\)</p>

<h3 id="algorithm-4">Algorithm</h3>

<p>The following stochastic gradient HMC with friction has proper stationary distribution<br />
\(\begin{array}{l}
d x=\mathrm{M}^{-1} v d t \\
d v=-\nabla U(x) d t-\mathrm{BM}^{-1} v d t+(2 \mathrm{B})^{1 / 2} d B_{t}
\end{array}\)</p>

:ET